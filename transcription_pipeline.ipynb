{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# YouTube Transcription Pipeline with Self-Hosted Whisper\n",
    "\n",
    "This notebook implements a pipeline that:\n",
    "1. Downloads audio from YouTube videos\n",
    "2. Uses locally hosted Whisper model for transcription and translation (no API costs)\n",
    "3. Converts the output to PDF\n",
    "\n",
    "## Setup and Requirements\n",
    "\n",
    "- Python 3.8+\n",
    "- FFmpeg (for audio processing)\n",
    "- Required packages: yt-dlp, openai-whisper, torch, fpdf\n",
    "- GPU recommended but not required (CPU will be slower)\n",
    "\n",
    "## Paste the Youtube video link in the last cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages in Jupyter Notebook\n",
    "!pip install yt-dlp\n",
    "!pip install -U openai-whisper\n",
    "!pip install fpdf\n",
    "!pip install torch  # Skip this if torch is already installed or if you're using GPU and need a specific version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Install required dependencies\n",
    "!pip install yt_dlp fpdf requests python-dotenv torch transformers openai-whisper tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import yt_dlp\n",
    "import whisper\n",
    "from fpdf import FPDF\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from IPython.display import FileLink, display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories if they don't exist\n",
    "os.makedirs(\"downloads\", exist_ok=True)\n",
    "os.makedirs(\"transcripts\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language dictionary loaded with 31 languages\n"
     ]
    }
   ],
   "source": [
    "# Language options dictionary (language code: language name)\n",
    "LANGUAGE_OPTIONS = {\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"de\": \"German\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"bn\": \"Bengali\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"vi\": \"Vietnamese\",\n",
    "    \"th\": \"Thai\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ms\": \"Malay\",\n",
    "    \"fa\": \"Persian\",\n",
    "    \"he\": \"Hebrew\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"sv\": \"Swedish\",\n",
    "    \"da\": \"Danish\",\n",
    "    \"no\": \"Norwegian\",\n",
    "    \"fi\": \"Finnish\",\n",
    "    \"hu\": \"Hungarian\",\n",
    "    \"el\": \"Greek\",\n",
    "    \"ro\": \"Romanian\",\n",
    "    \"uk\": \"Ukrainian\"\n",
    "}\n",
    "\n",
    "print(\"Language dictionary loaded with\", len(LANGUAGE_OPTIONS), \"languages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Why not? Why not? Why not? Why not? I don't know. I don't know. Something else. Why not?\n",
      "\n",
      "Cleaned text:\n",
      "Why not? I don't know. Something else. Why not?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_repeated_phrases(text):\n",
    "    \"\"\"Clean up repeated phrases in the transcript text\n",
    "    \n",
    "    This function removes repetitive phrases like \"Why not? Why not? Why not?\"\n",
    "    that might appear in the transcript, making it more readable.\n",
    "    \"\"\"\n",
    "    # Common repeated phrases to look for\n",
    "    common_phrases = [\n",
    "        \"Why not?\", \n",
    "        \"I don't know.\", \n",
    "        \"I love you.\", \n",
    "        \"I'm not sure.\",\n",
    "        \"What is that?\", \n",
    "        \"I like you.\", \n",
    "        \"I'm a big fan of this movie.\",\n",
    "        \"You are so smart.\"\n",
    "    ]\n",
    "    \n",
    "    cleaned_text = text\n",
    "    \n",
    "    # Clean up common repeated phrases\n",
    "    for phrase in common_phrases:\n",
    "        # Replace 3+ consecutive occurrences with just one\n",
    "        pattern = f\"({re.escape(phrase)}\\\\s*){{3,}}\"\n",
    "        cleaned_text = re.sub(pattern, phrase + \" \", cleaned_text)\n",
    "        \n",
    "        # Replace 2 consecutive occurrences with just one\n",
    "        pattern = f\"({re.escape(phrase)}\\\\s*){{2}}\"\n",
    "        cleaned_text = re.sub(pattern, phrase + \" \", cleaned_text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Test the function with a sample text\n",
    "sample_text = \"Why not? Why not? Why not? Why not? I don't know. I don't know. Something else. Why not?\"\n",
    "print(\"Original text:\")\n",
    "print(sample_text)\n",
    "print(\"\\nCleaned text:\")\n",
    "print(clean_repeated_phrases(sample_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Whisper Model Size\n",
    "\n",
    "Choose the Whisper model size to use for transcription. Larger models are more accurate but require more memory and computational resources:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Selected model: tiny\n",
      "Model parameters: 39M\n",
      "Approx. required VRAM: ~1 GB\n",
      "\n",
      "Loading Whisper model 'tiny'...\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Select Whisper model size\n",
    "# Available models: \"tiny\", \"base\", \"small\", \"medium\", \"large\"\n",
    "# Larger models are more accurate but require more memory and compute\n",
    "# Recommendation: Start with \"base\" or \"small\" for a balance of speed and accuracy\n",
    "WHISPER_MODEL_SIZE = \"tiny\"  # Change this to your desired model size\n",
    "\n",
    "# Print available devices for running the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Display model size info\n",
    "model_sizes = {\n",
    "    \"tiny\": {\"parameters\": \"39M\", \"required_vram\": \"~1 GB\", \"english_only\": False},\n",
    "    \"base\": {\"parameters\": \"74M\", \"required_vram\": \"~1 GB\", \"english_only\": False},\n",
    "    \"small\": {\"parameters\": \"244M\", \"required_vram\": \"~2 GB\", \"english_only\": False},\n",
    "    \"medium\": {\"parameters\": \"769M\", \"required_vram\": \"~5 GB\", \"english_only\": False},\n",
    "    \"large\": {\"parameters\": \"1550M\", \"required_vram\": \"~10 GB\", \"english_only\": False},\n",
    "}\n",
    "\n",
    "print(f\"\\nSelected model: {WHISPER_MODEL_SIZE}\")\n",
    "print(f\"Model parameters: {model_sizes[WHISPER_MODEL_SIZE]['parameters']}\")\n",
    "print(f\"Approx. required VRAM: {model_sizes[WHISPER_MODEL_SIZE]['required_vram']}\")\n",
    "\n",
    "# Check if selected model is reasonable for your device\n",
    "if device == \"cpu\" and WHISPER_MODEL_SIZE in [\"medium\", \"large\"]:\n",
    "    print(\"\\nWARNING: You've selected a large model to run on CPU. This may be very slow.\")\n",
    "    print(\"Consider using a smaller model like 'base' or 'small' for better performance on CPU.\")\n",
    "\n",
    "# Load the model (this will download the model first time)\n",
    "print(f\"\\nLoading Whisper model '{WHISPER_MODEL_SIZE}'...\")\n",
    "model = whisper.load_model(WHISPER_MODEL_SIZE, device=device)\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define TranscriptionPipeline Class\n",
    "\n",
    "Now we'll implement the main pipeline class with methods for downloading, transcribing, and creating PDFs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptionPipeline:\n",
    "    def __init__(self, whisper_model=None):\n",
    "        \"\"\"Initialize the transcription pipeline with local Whisper model\"\"\"\n",
    "        self.whisper_model = whisper_model or model  # Use the globally loaded model\n",
    "        \n",
    "        # Create output directories if they don't exist\n",
    "        os.makedirs(\"downloads\", exist_ok=True)\n",
    "        os.makedirs(\"transcripts\", exist_ok=True)\n",
    "        \n",
    "    def remove_consecutive_duplicates(self, text):\n",
    "        \"\"\"Remove consecutive duplicate lines from transcription text\n",
    "        \n",
    "        This function removes repeated lines that appear consecutively in the transcript.\n",
    "        It preserves the timestamps and only removes content that's exactly the same.\n",
    "        \n",
    "        Example:\n",
    "        [00:01.000 --> 00:02.000]  Hello world.\n",
    "        [00:02.000 --> 00:03.000]  Hello world.\n",
    "        [00:03.000 --> 00:04.000]  Hello world.\n",
    "        \n",
    "        Becomes:\n",
    "        [00:01.000 --> 00:02.000]  Hello world.\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return text\n",
    "            \n",
    "        lines = text.split('\\n')\n",
    "        if len(lines) <= 1:\n",
    "            return text\n",
    "            \n",
    "        # Extract content after timestamps (the actual spoken text)\n",
    "        def extract_content(line):\n",
    "            parts = line.split(']  ')\n",
    "            if len(parts) > 1:\n",
    "                return parts[1].strip()\n",
    "            return line.strip()\n",
    "        \n",
    "        result = [lines[0]]  # Always keep the first line\n",
    "        \n",
    "        for i in range(1, len(lines)):\n",
    "            current_content = extract_content(lines[i])\n",
    "            prev_content = extract_content(result[-1])\n",
    "            \n",
    "            # Only add the line if it's not a duplicate of the previous line\n",
    "            if current_content != prev_content or current_content == \"\":\n",
    "                result.append(lines[i])\n",
    "                \n",
    "        return '\\n'.join(result)\n",
    "    \n",
    "    def download_audio(self, youtube_url):\n",
    "        \"\"\"Download audio from YouTube video\"\"\"\n",
    "        print(f\"Downloading audio from: {youtube_url}\")\n",
    "        \n",
    "        def sanitize_filename(s):\n",
    "            # Replace characters that are problematic in filenames\n",
    "            chars_to_replace = ['<', '>', ':', '\"', '/', '\\\\', '|', '?', '*']\n",
    "            for char in chars_to_replace:\n",
    "                s = s.replace(char, '_')\n",
    "            return s\n",
    "        \n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
    "            'restrictfilenames': True,  # Restrict filenames to ASCII chars\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }],\n",
    "        }\n",
    "        \n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(youtube_url, download=True)\n",
    "            # Create a sanitized version of the title for the file path\n",
    "            safe_title = sanitize_filename(info['title'])\n",
    "            audio_file = f\"downloads/{safe_title}.mp3\"\n",
    "            print(f\"Audio downloaded: {audio_file}\")\n",
    "            return audio_file, info['title']\n",
    "    \n",
    "    def detect_language(self, audio_file):\n",
    "        \"\"\"Detect the language of the audio file\"\"\"\n",
    "        print(\"Detecting original language...\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(audio_file):\n",
    "            # Try to find the actual file that might have been renamed by yt-dlp\n",
    "            possible_files = [f for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
    "            if possible_files:\n",
    "                print(f\"Original file path '{audio_file}' not found. Using '{os.path.join('downloads', possible_files[0])}'\")\n",
    "                audio_file = os.path.join(\"downloads\", possible_files[0])\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "        \n",
    "        # Load audio and detect language\n",
    "        audio = whisper.load_audio(audio_file)\n",
    "        audio = whisper.pad_or_trim(audio)\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(self.whisper_model.device)\n",
    "        _, probs = self.whisper_model.detect_language(mel)\n",
    "        detected_lang = max(probs, key=probs.get)\n",
    "        \n",
    "        # Get language name if available\n",
    "        lang_name = LANGUAGE_OPTIONS.get(detected_lang, \"Unknown\")\n",
    "        print(f\"Detected language: {detected_lang} ({lang_name}) - confidence: {probs[detected_lang]:.2f}\")\n",
    "        \n",
    "        return detected_lang, probs[detected_lang]\n",
    "    \n",
    "    def transcribe_audio(self, audio_file, target_language):\n",
    "        \"\"\"Transcribe audio using local Whisper model and translate to target language\"\"\"\n",
    "        print(f\"Transcribing audio to {target_language} using local Whisper model...\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(audio_file):\n",
    "            # Try to find the actual file that might have been renamed by yt-dlp\n",
    "            possible_files = [f for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
    "            if possible_files:\n",
    "                print(f\"Original file path '{audio_file}' not found. Using '{os.path.join('downloads', possible_files[0])}'\")\n",
    "                audio_file = os.path.join(\"downloads\", possible_files[0])\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "        \n",
    "        # First detect the language\n",
    "        detected_lang, confidence = self.detect_language(audio_file)\n",
    "        \n",
    "        # Use this for translation to target language\n",
    "        if target_language != \"en\":\n",
    "            print(f\"Translating from {detected_lang} to {target_language}...\")\n",
    "            # whisper.decode can translate to different languages\n",
    "            result = self.whisper_model.transcribe(\n",
    "                audio_file,\n",
    "                task=\"translate\",\n",
    "                language=target_language,\n",
    "                verbose=True\n",
    "            )\n",
    "        else:\n",
    "            # Regular transcription in original language\n",
    "            result = self.whisper_model.transcribe(\n",
    "                audio_file,\n",
    "                language=target_language,\n",
    "                verbose=True\n",
    "            )\n",
    "        \n",
    "        # Process the transcription text to remove consecutive duplicates\n",
    "        cleaned_text = self.remove_consecutive_duplicates(result[\"text\"])\n",
    "        \n",
    "        # Add detected language info to the result\n",
    "        result_with_lang = {\n",
    "            \"text\": cleaned_text,\n",
    "            \"detected_language\": detected_lang,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "            \n",
    "        # Return the text transcription and detected language\n",
    "        return result_with_lang\n",
    "    \n",
    "    def create_pdf(self, transcript_result, title, target_language, output_file=None):\n",
    "        \"\"\"Generate PDF from transcription text\"\"\"\n",
    "        # Extract text and language info\n",
    "        text = transcript_result[\"text\"]\n",
    "        detected_lang = transcript_result[\"detected_language\"]\n",
    "        \n",
    "        # Apply additional cleaning to remove repeated phrases\n",
    "        text = clean_repeated_phrases(text)\n",
    "        \n",
    "        # Create a sanitized version of the title for the filename\n",
    "        safe_title = \"\".join([c if c.isalnum() else \"_\" for c in title])\n",
    "        \n",
    "        if output_file is None:\n",
    "            # Use the video title for the PDF filename\n",
    "            output_file = f\"transcripts/{safe_title}_{target_language}.pdf\"\n",
    "        \n",
    "        print(f\"Creating PDF: {output_file}\")\n",
    "        \n",
    "        # Get language names\n",
    "        source_lang_name = LANGUAGE_OPTIONS.get(detected_lang, \"Unknown\")\n",
    "        target_lang_name = LANGUAGE_OPTIONS.get(target_language, \"Unknown\")\n",
    "        \n",
    "        try:\n",
    "            # Clean the text to remove problematic characters\n",
    "            clean_text = \"\"\n",
    "            for char in text:\n",
    "                try:\n",
    "                    # Test if character can be encoded\n",
    "                    char.encode('latin-1')\n",
    "                    clean_text += char\n",
    "                except UnicodeEncodeError:\n",
    "                    # Replace characters that can't be encoded with a space\n",
    "                    clean_text += \" \"\n",
    "            \n",
    "            # Initialize PDF\n",
    "            pdf = FPDF()\n",
    "            pdf.add_page()\n",
    "            pdf.set_auto_page_break(auto=True, margin=15)\n",
    "            \n",
    "            # Add title with proper formatting for long titles\n",
    "            pdf.set_font(\"Arial\", \"B\", 16)\n",
    "            \n",
    "            # Format the title to handle long titles\n",
    "            full_title = f\"Transcript: {title}\"\n",
    "            # Calculate maximum width for title (page width minus margins)\n",
    "            max_width = pdf.w - 40  # 20mm margin on each side\n",
    "            \n",
    "            # If title is too long, use multi_cell instead of cell\n",
    "            if pdf.get_string_width(full_title) > max_width:\n",
    "                pdf.multi_cell(0, 10, full_title, align=\"C\")\n",
    "            else:\n",
    "                pdf.cell(0, 10, full_title, ln=True, align=\"C\")\n",
    "            \n",
    "            pdf.ln(10)\n",
    "            \n",
    "            # Add language info\n",
    "            pdf.set_font(\"Arial\", \"I\", 12)\n",
    "            pdf.cell(0, 10, f\"Original language: {detected_lang} ({source_lang_name})\", ln=True)\n",
    "            pdf.cell(0, 10, f\"Output language: {target_language} ({target_lang_name})\", ln=True)\n",
    "            pdf.ln(5)\n",
    "            \n",
    "            # Add transcript text\n",
    "            pdf.set_font(\"Arial\", \"\", 12)\n",
    "            \n",
    "            # Split text into lines and add to PDF\n",
    "            pdf.multi_cell(0, 10, clean_text)\n",
    "            \n",
    "            # Save PDF\n",
    "            pdf.output(output_file)\n",
    "            \n",
    "            return output_file\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating PDF: {str(e)}\")\n",
    "            \n",
    "            # Fallback: Save as text file instead\n",
    "            txt_file = output_file.replace(\".pdf\", \".txt\")\n",
    "            print(f\"Saving as text file instead: {txt_file}\")\n",
    "            \n",
    "            with open(txt_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"Transcript: {title}\\n\\n\")\n",
    "                f.write(f\"Original language: {detected_lang} ({source_lang_name})\\n\")\n",
    "                f.write(f\"Output language: {target_language} ({target_lang_name})\\n\\n\")\n",
    "                f.write(text)\n",
    "            \n",
    "            return txt_file\n",
    "    \n",
    "    def process_video(self, youtube_url, target_language):\n",
    "        \"\"\"Process a YouTube video: download, transcribe, and create PDF\"\"\"\n",
    "        try:\n",
    "            # Step 1: Download audio\n",
    "            print(\"Step 1/3: Downloading audio...\")\n",
    "            audio_file, title = self.download_audio(youtube_url)\n",
    "            \n",
    "            # Step 2: Transcribe and translate audio\n",
    "            print(\"Step 2/3: Transcribing audio...\")\n",
    "            transcript_result = self.transcribe_audio(audio_file, target_language)\n",
    "            \n",
    "            # Step 3: Create PDF\n",
    "            print(\"Step 3/3: Creating PDF...\")\n",
    "            pdf_file = self.create_pdf(transcript_result, title, target_language)\n",
    "            \n",
    "            # Display language information\n",
    "            detected_lang = transcript_result[\"detected_language\"]\n",
    "            source_lang_name = LANGUAGE_OPTIONS.get(detected_lang, \"Unknown\")\n",
    "            target_lang_name = LANGUAGE_OPTIONS.get(target_language, \"Unknown\")\n",
    "            \n",
    "            print(f\"Video language: {detected_lang} ({source_lang_name})\")\n",
    "            print(f\"Output language: {target_language} ({target_lang_name})\")\n",
    "            print(f\"Process completed successfully! PDF saved at: {pdf_file}\")\n",
    "            \n",
    "            return pdf_file\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in pipeline: {str(e)}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run the Pipeline\n",
    "\n",
    "Now let's use our pipeline class to process a YouTube video:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated Feature: Support for Python version 3.8 has been deprecated. Please update to Python 3.9 or above\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using language: en (English)\n",
      "Starting transcription pipeline...\n",
      "Step 1/3: Downloading audio...\n",
      "Downloading audio from: https://www.youtube.com/watch?v=3dKSBfRMmdU&t=1s\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=3dKSBfRMmdU&t=1s\n",
      "[youtube] 3dKSBfRMmdU: Downloading webpage\n",
      "[youtube] 3dKSBfRMmdU: Downloading ios player API JSON\n",
      "[youtube] 3dKSBfRMmdU: Downloading mweb player API JSON\n",
      "[youtube] 3dKSBfRMmdU: Downloading player 94f771d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/94f771d8/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] 3dKSBfRMmdU: nsig extraction failed: Some formats may be missing\n",
      "         n = Roynya_o9oQ7C4hxc ; player = https://www.youtube.com/s/player/94f771d8/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/94f771d8/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] 3dKSBfRMmdU: nsig extraction failed: Some formats may be missing\n",
      "         n = ead6d5-LpEgnd-zmH ; player = https://www.youtube.com/s/player/94f771d8/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 3dKSBfRMmdU: Downloading m3u8 information\n",
      "[info] 3dKSBfRMmdU: Downloading 1 format(s): 251\n",
      "[download] Destination: downloads\\MOST_CRINGE_FEED_EVARIDI_FIRST_VIDEO_II_KAKARAKAYTALKS.webm\n",
      "[download] 100% of   12.63MiB in 00:00:03 at 3.85MiB/s     \n",
      "[ExtractAudio] Destination: downloads\\MOST_CRINGE_FEED_EVARIDI_FIRST_VIDEO_II_KAKARAKAYTALKS.mp3\n",
      "Deleting original file downloads\\MOST_CRINGE_FEED_EVARIDI_FIRST_VIDEO_II_KAKARAKAYTALKS.webm (pass -k to keep)\n",
      "Audio downloaded: downloads/MOST CRINGE FEED EVARIDI___ __ FIRST VIDEO II KAKARAKAYTALKS.mp3\n",
      "Step 2/3: Transcribing audio...\n",
      "Transcribing audio to en using local Whisper model...\n",
      "Original file path 'downloads/MOST CRINGE FEED EVARIDI___ __ FIRST VIDEO II KAKARAKAYTALKS.mp3' not found. Using 'downloads\\MOST CRINGE FEED EVARIDI？？？ ｜｜ FIRST VIDEO II KAKARAKAYTALKS.mp3'\n",
      "Detecting original language...\n",
      "Detected language: te (Unknown) - confidence: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:05.000]  Hi friends welcome to our channel, get up,\n",
      "[00:05.000 --> 00:07.000]  What are you doing here?\n",
      "[00:07.000 --> 00:09.000]  I am going to do the first thing I do.\n",
      "[00:09.000 --> 00:14.000]  I am going to do my first youtube video of French couple 9 coverage of the star and dates.\n",
      "[00:14.000 --> 00:17.000]  I was going to do a lot of things.\n",
      "[00:17.000 --> 00:20.000]  I was going to do a lot of things.\n",
      "[00:20.000 --> 00:23.000]  I have a lot of things to do.\n",
      "[00:23.000 --> 00:25.000]  Why not? Why not?\n",
      "[00:26.000 --> 00:28.000]  Why not? Why not?\n",
      "[00:28.000 --> 00:30.000]  Why not? Why not?\n",
      "[00:30.000 --> 00:32.000]  Why not?\n",
      "[00:32.000 --> 00:34.000]  Why not?\n",
      "[00:34.000 --> 00:35.000]  Why not?\n",
      "[00:35.000 --> 00:36.000]  Why not?\n",
      "[00:36.000 --> 00:37.000]  Why not?\n",
      "[00:37.000 --> 00:38.000]  Why not?\n",
      "[00:38.000 --> 00:39.000]  Why not?\n",
      "[00:39.000 --> 00:40.000]  Why not?\n",
      "[00:40.000 --> 00:41.000]  I did a mistake.\n",
      "[00:41.000 --> 00:43.000]  Okay, I will see.\n",
      "[00:43.000 --> 00:44.000]  I will see.\n",
      "[00:44.000 --> 00:48.000]  Anyways, so many first youtube videos that I have already answered.\n",
      "[00:48.000 --> 00:50.000]  I am a female teacher.\n",
      "[00:51.000 --> 00:58.000]  As I work like this I got a video for products and\n",
      "[00:58.000 --> 00:59.000]  Sounds like a 저what?\n",
      "[00:59.000 --> 01:00.000]  Then I will do my就是.\n",
      "[01:00.000 --> 01:02.000]  Hold on, there is no character.\n",
      "[01:02.000 --> 01:03.000]  I want to know.\n",
      "[01:03.000 --> 01:04.000]  Hey mom.\n",
      "[01:04.000 --> 01:05.460]  What is this mom\n",
      "[01:05.480 --> 01:06.000]  I am doing\n",
      "[01:06.000 --> 01:07.000]  She was walking in the airport\n",
      "[01:07.000 --> 01:08.000]  I have only nothing to do\n",
      "[01:08.000 --> 01:08.100]  What\n",
      "[01:08.100 --> 01:10.000]  What is this house\n",
      "[01:10.000 --> 01:11.040]  Which is done before\n",
      "[01:11.040 --> 01:12.000]  I keep counting echoes\n",
      "[01:12.000 --> 01:13.000]  Where are you from now?\n",
      "[01:13.000 --> 01:14.000]  A Instagram\n",
      "[01:14.000 --> 01:16.000]  I use theら theatre\n",
      "[01:16.000 --> 01:18.000]  I also use theら-protection\n",
      "[01:18.000 --> 01:20.660]  So the baby begins talking..\n",
      "[01:20.660 --> 01:22.040]  Yes, its normal vac retaliate\n",
      "[01:22.040 --> 01:22.800]  Sh32 that means killed\n",
      "[01:22.800 --> 01:25.880]  In the same issue he increasing her growth\n",
      "[01:25.880 --> 01:27.240]  He he increasing the growth\n",
      "[01:35.240 --> 01:37.240]  Can you lend me your poison\n",
      "[01:37.400 --> 01:38.680]  You dont опыт wure\n",
      "[01:41.080 --> 01:43.000]  But you are talking\n",
      "[01:43.000 --> 01:45.080]  We dont have the right to do this\n",
      "[01:45.080 --> 01:50.160]  See if you need a big camera for free if you want a video for me\n",
      "[01:50.420 --> 01:53.100]  How much do you want for this?\n",
      "[01:58.180 --> 01:59.920]  This is called fatata\n",
      "[02:01.640 --> 02:06.620]  This is called chad song\n",
      "[02:07.120 --> 02:11.200]  You need a Inth acoustic guitar\n",
      "[02:11.780 --> 02:15.020]  Now the guitar becomesWoman's car\n",
      "[02:15.080 --> 02:16.720]  Face it to your shoulder\n",
      "[02:16.740 --> 02:18.680]  Suppose you hit 100 m\n",
      "[02:18.760 --> 02:21.020]  I don't know if I hit 100 m\n",
      "[02:21.040 --> 02:23.940]  Us notice a little bit\n",
      "[02:25.300 --> 02:26.980]  But is it better that the food was made\n",
      "[02:27.280 --> 02:28.080]  Young была\n",
      "[02:28.600 --> 02:30.060]  But no cheese\n",
      "[02:30.060 --> 02:31.080]  No cheese\n",
      "[02:31.520 --> 02:32.320]  I saw it\n",
      "[02:32.320 --> 02:34.240] Freésur\n",
      "[02:36.160 --> 02:37.060]  I protested\n",
      "[02:40.800 --> 02:41.960]  Subscribe\n",
      "[02:41.960 --> 02:42.960]  What's this?\n",
      "[02:42.960 --> 02:43.960]  What's this?\n",
      "[02:43.960 --> 02:44.960]  What's this?\n",
      "[02:44.960 --> 02:45.960]  Come on, come on.\n",
      "[02:45.960 --> 02:46.960]  Come on.\n",
      "[02:46.960 --> 02:48.960]  I'm going to show you the kids.\n",
      "[02:48.960 --> 02:50.960]  I'm going to show you the kids.\n",
      "[02:50.960 --> 02:51.960]  Come on.\n",
      "[02:51.960 --> 02:53.960]  What's this?\n",
      "[02:53.960 --> 02:56.960]  You can eat yourself.\n",
      "[02:56.960 --> 02:58.960]  I'm not going to show you.\n",
      "[02:58.960 --> 02:59.960]  Okay.\n",
      "[02:59.960 --> 03:00.960]  Grinch.\n",
      "[03:00.960 --> 03:01.960]  Okay.\n",
      "[03:01.960 --> 03:02.960]  Grinch ready.\n",
      "[03:02.960 --> 03:08.960]  I'm going to tell you 10 and like all 8.5 sub run and crinch rating.\n",
      "[03:08.960 --> 03:10.960]  5 minutes at a time.\n",
      "[03:10.960 --> 03:11.960]  I'm going to show you 10.\n",
      "[03:11.960 --> 03:13.960]  I'm going to show you 10.\n",
      "[03:13.960 --> 03:15.960]  I'm going to show you 10.\n",
      "[03:15.960 --> 03:17.960]  I'm going to show you 10.\n",
      "[03:17.960 --> 03:21.960]  I require all my roommates to use the same toothbrushes me.\n",
      "[03:21.960 --> 03:22.960]  Hi.\n",
      "[03:22.960 --> 03:24.960]  My name is Ivy Bloom and these are my house rules.\n",
      "[03:24.960 --> 03:28.960]  Everyone must wake up at 7 a.m. and meet in the living room where we create a\n",
      "[03:28.960 --> 03:44.960]  assault circle in the chants set of 47 affirmations.\n",
      "[03:44.960 --> 03:45.960]  Reeekerah.\n",
      "[03:45.960 --> 03:46.960]  Reeekerah.\n",
      "[03:46.960 --> 03:47.960]  Reeekerah.\n",
      "[03:47.960 --> 03:48.960]  Domny.\n",
      "[03:48.960 --> 03:49.960]  Domny.\n",
      "[03:49.960 --> 03:50.960]  Reeekerah.\n",
      "[03:50.960 --> 03:51.960]  Mother.\n",
      "[03:51.960 --> 03:52.960]  Reeekerah.\n",
      "[03:52.960 --> 03:54.960]  Reeekerah.\n",
      "[03:54.960 --> 03:55.960]  Reeekerah.\n",
      "[03:59.960 --> 04:00.960]  Reeekerah.\n",
      "[04:01.960 --> 04:04.960]  Reeekerah.\n",
      "[04:05.960 --> 04:07.960]  This is XP.\n",
      "[04:07.960 --> 04:11.420]  Keep playing!\n",
      "[04:37.960 --> 04:44.420] ếtremos\n",
      "[04:53.140 --> 04:59.620]  уже это.\n",
      "[05:07.960 --> 05:21.940]  Take them out of the cottonishing tools!\n",
      "[05:21.940 --> 05:23.940]  Anyway...\n",
      "[05:25.960 --> 05:29.960]  I am sure he would catch me but why should he catch me?\n",
      "[05:30.460 --> 05:32.960]  I don't know why people say that...\n",
      "[05:32.960 --> 05:37.200]  I will swallow all of them because I ignore them\n",
      "[05:37.200 --> 05:38.820]  I don't know\n",
      "[05:40.100 --> 05:41.500]  I don't see my no. 20\n",
      "[05:42.640 --> 05:45.560]  Shekana is mixing\n",
      "[05:48.560 --> 05:49.480]  What?\n",
      "[05:49.480 --> 05:51.100]  What is her?\n",
      "[05:51.100 --> 05:52.640]  You love him.\n",
      "[05:55.420 --> 05:57.940]  His brotherHelio is my uncle uncle.\n",
      "[06:03.040 --> 06:03.820]  Wee.\n",
      "[06:07.920 --> 06:09.780]  Oh no our Canadian bachelor.\n",
      "[06:10.780 --> 06:11.440]  Oh how hard we are.\n",
      "[06:13.980 --> 06:15.260]  You trying to beat a man.\n",
      "[06:15.520 --> 06:16.200]  I really can't tell you my brother is young.\n",
      "[06:16.200 --> 06:18.540]  actually, local food**\n",
      "[06:18.540 --> 06:19.580]  This is香港 burger\n",
      "[06:19.580 --> 06:21.460]  to break fairly good chargey\n",
      "[06:22.980 --> 06:25.460]  I also got almost 300 what did you get a heart coating?\n",
      "[06:26.460 --> 06:28.460]  Look at this meat\n",
      "[06:28.540 --> 06:31.340]  rice with a wood candel\n",
      "[06:31.340 --> 06:33.820]  goat\n",
      "[06:33.820 --> 06:35.720]  buying leek\n",
      "[06:39.900 --> 06:41.600]  last you'll listen to me\n",
      "[06:42.100 --> 06:44.600]  Madam what is it\n",
      "[06:44.600 --> 06:46.100]  very loose\n",
      "[06:50.100 --> 06:51.600]  let's find it\n",
      "[06:59.540 --> 07:00.100]  ok\n",
      "[07:04.280 --> 07:04.780]  ar jalang\n",
      "[07:04.920 --> 07:05.340]  right hand\n",
      "[07:05.340 --> 07:05.580]  dear\n",
      "[07:10.460 --> 07:11.420]  he looks at what?\n",
      "[07:12.420 --> 07:13.440]  He looks upper\n",
      "[07:14.600 --> 07:16.160]  you\n",
      "[07:19.440 --> 07:20.440]  Yes\n",
      "[07:24.200 --> 07:25.840]  Allooked\n",
      "[07:28.300 --> 07:30.380]  What is the point?\n",
      "[07:30.380 --> 07:31.520]  Not there\n",
      "[07:32.580 --> 07:36.240]  Will be better\n",
      "[07:36.240 --> 07:38.240]  That isn't possible\n",
      "[07:38.640 --> 07:41.040]  About 70-year humanoids\n",
      "[07:41.040 --> 07:43.080]  He is the biological cure\n",
      "[07:43.080 --> 07:46.700]  I feel so lucky Sw Kollege, don't leave him in the left.\n",
      "[07:48.080 --> 07:50.360]  If you haven't said that...\n",
      "[07:51.480 --> 07:56.320]  I scolded him for a thought that...?\n",
      "[07:56.480 --> 07:58.160]  Don't forget that girl!\n",
      "[07:58.160 --> 08:00.960]  I should not!\n",
      "[08:04.400 --> 08:06.400]  Khanna does it.\n",
      "[08:06.400 --> 08:08.400]  His name is K Xiao Ge.\n",
      "[08:08.400 --> 08:09.640]  I didn't listen to that guy by name.\n",
      "[08:09.640 --> 08:12.140]  Bye!\n",
      "[08:15.620 --> 08:17.460]  Every time we leave\n",
      "[08:20.800 --> 08:22.840]  at 7 am\n",
      "[08:24.840 --> 08:26.840]  Sun.\n",
      "[08:27.520 --> 08:30.320]  Anden District\n",
      "[08:30.320 --> 08:31.580]  Not frequently right.\n",
      "[08:35.080 --> 08:36.120]  Yeah.\n",
      "[08:37.740 --> 08:39.740]  When did he come and come and tell you, we're taking a really good time.\n",
      "[08:40.540 --> 08:43.960]  I was eating when I was twenty.\n",
      "[08:44.260 --> 08:45.760]  How many minutes was it?\n",
      "[08:50.140 --> 08:51.140]  How many minutes did he finish?\n",
      "[08:54.920 --> 08:56.760]  Great, especially the bass one handed over to me.\n",
      "[09:00.320 --> 09:01.320]  What?\n",
      "[09:01.320 --> 09:02.320]  What?\n",
      "[09:02.320 --> 09:03.320]  What?\n",
      "[09:03.320 --> 09:04.320]  What?\n",
      "[09:04.320 --> 09:05.320]  What?\n",
      "[09:05.320 --> 09:06.320]  What?\n",
      "[09:06.320 --> 09:08.320]  What?\n",
      "[09:08.320 --> 09:10.320]  What?\n",
      "[09:10.320 --> 09:11.320]  What?\n",
      "[09:11.320 --> 09:15.320]  This is the only thing that is going to happen.\n",
      "[09:15.320 --> 09:16.320]  Are you ready?\n",
      "[09:16.320 --> 09:17.320]  Please kind of pass.\n",
      "[09:17.320 --> 09:19.320]  I'm not ready to do it.\n",
      "[09:23.320 --> 09:24.320]  Suri, do you want to do it?\n",
      "[09:24.320 --> 09:25.320]  I want to do it.\n",
      "[09:25.320 --> 09:26.320]  I want to do it.\n",
      "[09:26.320 --> 09:27.320]  Do you want to do it?\n",
      "[09:27.320 --> 09:28.320]  Do you want to do it?\n",
      "[09:28.320 --> 09:29.320]  No.\n",
      "[09:29.320 --> 09:30.320]  Or is my mama?\n",
      "[09:30.320 --> 09:31.320]  No.\n",
      "[09:31.320 --> 09:32.320]  How can I lose my heart?\n",
      "[09:32.320 --> 09:34.320]  Where do you think they are?\n",
      "[09:34.320 --> 09:35.820]  Hahahaa..\n",
      "[09:35.820 --> 09:37.320]  Hahaha..\n",
      "[09:37.320 --> 09:41.320]  Then how can they pass the end in such a way.\n",
      "[09:41.320 --> 09:44.320]  Taking the photo...\n",
      "[09:44.320 --> 09:45.320]  ...my self...\n",
      "[09:45.320 --> 09:46.320]  Ahhh..\n",
      "[09:46.320 --> 09:47.320]  When I told Suri.\n",
      "[09:47.320 --> 09:48.320]  Suri was saved.\n",
      "[09:48.320 --> 09:49.320]  Then we passed that place.\n",
      "[09:49.320 --> 09:50.320]  Hey...\n",
      "[09:51.320 --> 09:52.320]  Suri!\n",
      "[09:52.320 --> 09:54.320]  The story of my brother.\n",
      "[09:54.320 --> 09:55.320]  Pringit.\n",
      "[09:55.320 --> 09:59.700]  Because, sometimes, a thing happens but not it happens again.\n",
      "[10:09.940 --> 10:12.160]  What are those kids doing?\n",
      "[10:12.160 --> 10:21.180]  This is nearly 8 hours and I am going to take more bad shoes and give them to me.\n",
      "[10:21.180 --> 10:22.920] なんです\n",
      "[10:22.920 --> 10:24.680]  oh good\n",
      "[10:25.340 --> 10:26.760]  Thank you\n",
      "[10:31.080 --> 10:33.080]  Aities\n",
      "[10:33.760 --> 10:35.240]  Wait\n",
      "[10:42.140 --> 10:43.740]  Why are you putting up everything?\n",
      "[10:43.740 --> 10:53.180]  Who was 3,\n",
      "[10:53.180 --> 10:55.180]  I'm not going to get a lunch.\n",
      "[10:55.180 --> 10:56.180]  I'm going to get a lunch.\n",
      "[10:56.180 --> 10:57.180]  I'm going to get a lunch.\n",
      "[10:57.180 --> 10:58.180]  Yabro.\n",
      "[10:59.180 --> 11:00.180]  Riyakana.\n",
      "[11:00.180 --> 11:01.180]  Riyayabro.\n",
      "[11:01.180 --> 11:02.180]  Dome.\n",
      "[11:02.180 --> 11:03.180]  According to Dome.\n",
      "[11:03.180 --> 11:04.180]  Riyayabro.\n",
      "[11:07.180 --> 11:08.180]  Shit.\n",
      "[11:08.180 --> 11:09.180]  It's my day.\n",
      "[11:09.180 --> 11:10.180]  I'm going to get a lunch.\n",
      "[11:17.180 --> 11:19.180]  I'm getting ready for this.\n",
      "[11:19.180 --> 11:20.180]  Prince.\n",
      "[11:21.180 --> 11:22.180]  King.\n",
      "[11:22.180 --> 11:23.180]  King.\n",
      "[11:27.180 --> 11:29.180]  I have to receive 4 milk.\n",
      "[11:34.180 --> 11:35.180]  That's enough.\n",
      "[11:35.180 --> 11:37.180]  This cow...\n",
      "[11:41.180 --> 11:43.180]  Riyakana.\n",
      "[11:43.180 --> 11:44.180]  Do me a favor.\n",
      "[11:44.180 --> 11:45.180]  Do not drop her.\n",
      "[11:45.180 --> 11:46.180]  Do me a favor.\n",
      "[11:46.180 --> 11:46.500]  Kaif, gentlemen.\n",
      "[11:47.220 --> 11:48.180]  King, please!\n",
      "[11:48.180 --> 11:50.700]  I don't know how to pronounce it.\n",
      "[11:50.700 --> 11:53.460]  I don't know how to pronounce it.\n",
      "[11:53.460 --> 11:56.100]  You feel like you're over a lot.\n",
      "[11:56.100 --> 11:58.020]  So your sleeve is cringey and butter.\n",
      "[11:58.020 --> 11:59.500]  But it's a content in gold.\n",
      "[11:59.500 --> 12:03.500]  I don't know how to pronounce it.\n",
      "[12:03.500 --> 12:05.860]  I'm a big fan of this movie.\n",
      "[12:07.060 --> 12:09.060]  I don't know.\n",
      "[12:09.060 --> 12:12.180]  I'm a loser. I'm a loser.\n",
      "[12:12.180 --> 12:14.180]  I don't know how to pronounce it.\n",
      "[12:14.180 --> 12:17.140]  I don't know how to pronounce it.\n",
      "[12:18.180 --> 12:20.620]  ToGermanos\n",
      "[12:48.180 --> 13:15.460]  B\n",
      "[13:15.460 --> 13:17.460]  I'm not a Muslim\n",
      "[13:17.460 --> 13:19.460]  I'm not a Muslim\n",
      "[13:25.460 --> 13:26.460]  Adam\n",
      "[13:26.460 --> 13:27.460]  Right answer\n",
      "[13:27.460 --> 13:28.460]  Go on\n",
      "[13:28.460 --> 13:29.460]  Right answer\n",
      "[13:29.460 --> 13:30.460]  And then we go\n",
      "[13:30.460 --> 13:31.460]  Right answer\n",
      "[13:32.460 --> 13:33.460]  Right answer\n",
      "[13:33.460 --> 13:34.460]  Right answer\n",
      "[13:34.460 --> 13:36.460]  And we are right answer\n",
      "[13:36.460 --> 13:37.460]  Yes\n",
      "[13:37.460 --> 13:38.460]  Yes\n",
      "[13:38.460 --> 13:39.460]  Yes\n",
      "[13:39.460 --> 13:40.460]  Yes\n",
      "[13:40.460 --> 13:41.460]  I'm not a Muslim\n",
      "[13:45.460 --> 13:47.460]  I'm not a Muslim\n",
      "[13:47.460 --> 13:50.460]  So the most crazy thing\n",
      "[13:50.460 --> 13:51.460]  I'm not a Muslim\n",
      "[13:51.460 --> 13:52.460]  I'm not a Muslim\n",
      "[13:54.460 --> 13:58.460]  I'm going to read one million likes\n",
      "[13:58.460 --> 14:00.460]  So please, please, please, please\n",
      "[14:00.460 --> 14:03.460]  Please, please, please, please\n",
      "[14:03.460 --> 14:05.460]  Please, please, please, please\n",
      "[14:05.460 --> 14:07.460]  Please, please, please\n",
      "Step 3/3: Creating PDF...\n",
      "Creating PDF: transcripts/MOST_CRINGE_FEED_EVARIDI_______FIRST_VIDEO_II_KAKARAKAYTALKS_en.pdf\n",
      "Video language: te (Unknown)\n",
      "Output language: en (English)\n",
      "Process completed successfully! PDF saved at: transcripts/MOST_CRINGE_FEED_EVARIDI_______FIRST_VIDEO_II_KAKARAKAYTALKS_en.pdf\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**PDF generated successfully!** [Open PDF](transcripts/MOST_CRINGE_FEED_EVARIDI_______FIRST_VIDEO_II_KAKARAKAYTALKS_en.pdf)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the transcription pipeline with the local Whisper model\n",
    "pipeline = TranscriptionPipeline(whisper_model=model)\n",
    "\n",
    "# Set the YouTube URL and target language\n",
    "youtube_url = \"https://www.youtube.com/watch?v=3dKSBfRMmdU&t=1s\"  # Replace with your desired YouTube video\n",
    "\n",
    "# Use the selected language from the dropdown above\n",
    "try:\n",
    "    # Use the selected language from the dropdown if available\n",
    "    target_language = selected_language\n",
    "except NameError:\n",
    "    # Fall back to default if dropdown wasn't used\n",
    "    target_language = \"en\"  # Language code (e.g., 'en', 'es', 'fr', 'de', 'ja', etc.)\n",
    "\n",
    "print(f\"Using language: {target_language} ({LANGUAGE_OPTIONS.get(target_language, 'Unknown')})\")\n",
    "\n",
    "# Run the pipeline\n",
    "print(\"Starting transcription pipeline...\")\n",
    "pdf_path = pipeline.process_video(youtube_url, target_language)\n",
    "\n",
    "# Display link to the generated PDF if successful\n",
    "if pdf_path:\n",
    "    display(Markdown(f\"**PDF generated successfully!** [Open PDF]({pdf_path})\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Batch Processing Multiple Videos\n",
    "\n",
    "If you want to process multiple videos at once:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of YouTube URLs and their target languages\n",
    "# # Use our language options dictionary to select desired languages\n",
    "# videos_to_process = [\n",
    "#     {\"url\": \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\", \"language\": \"en\"},  # English\n",
    "#     {\"url\": \"https://www.youtube.com/watch?v=VIDEO_ID_2\", \"language\": \"es\"},   # Spanish\n",
    "#     # Add more videos as needed\n",
    "#     # You can use any language code from LANGUAGE_OPTIONS dictionary\n",
    "# ]\n",
    "\n",
    "# # Print available languages as a reminder\n",
    "# print(\"Available languages for batch processing:\")\n",
    "# print(\", \".join([f\"{code}: {name}\" for code, name in list(LANGUAGE_OPTIONS.items())[:10]]))\n",
    "# print(f\"... and {len(LANGUAGE_OPTIONS) - 10} more languages (see language options cell above)\")\n",
    "\n",
    "# # Process each video\n",
    "# results = []\n",
    "# for video in videos_to_process:\n",
    "#     print(f\"\\nProcessing video: {video['url']} in {video['language']}\")\n",
    "#     pdf_path = pipeline.process_video(video[\"url\"], video[\"language\"])\n",
    "#     results.append({\n",
    "#         \"url\": video[\"url\"],\n",
    "#         \"language\": video[\"language\"],\n",
    "#         \"success\": pdf_path is not None,\n",
    "#         \"pdf_path\": pdf_path\n",
    "#     })\n",
    "\n",
    "# # Display results\n",
    "# print(\"\\nProcessing Results:\")\n",
    "# for i, result in enumerate(results, 1):\n",
    "#     status = \"✅ Success\" if result[\"success\"] else \"❌ Failed\"\n",
    "#     print(f\"{i}. {status} - {result['url']} ({result['language']})\")\n",
    "#     if result[\"success\"]:\n",
    "#         print(f\"   PDF: {result['pdf_path']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
